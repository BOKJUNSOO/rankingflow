{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------------+\n",
      "|row_number|level|         need_exp|\n",
      "+----------+-----+-----------------+\n",
      "|      NULL| NULL|             NULL|\n",
      "|         0|  260|1.731919984062E12|\n",
      "|         1|  261|1.749239183902E12|\n",
      "|         2|  262|1.766731575741E12|\n",
      "|         3|  263|1.784398891498E12|\n",
      "|         4|  264|1.802242880412E12|\n",
      "|         5|  265|2.342915744535E12|\n",
      "|         6|  266| 2.36634490198E12|\n",
      "|         7|  267|2.390008350999E12|\n",
      "|         8|  268|2.413908434508E12|\n",
      "+----------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-----------------+\n",
      "|level|         need_exp|\n",
      "+-----+-----------------+\n",
      "|  260|1.731919984062E12|\n",
      "|  261|1.749239183902E12|\n",
      "|  262|1.766731575741E12|\n",
      "|  263|1.784398891498E12|\n",
      "|  264|1.802242880412E12|\n",
      "|  265|2.342915744535E12|\n",
      "|  266| 2.36634490198E12|\n",
      "|  267|2.390008350999E12|\n",
      "|  268|2.413908434508E12|\n",
      "|  269|2.438047518853E12|\n",
      "+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## USER 테이블 build\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = (\n",
    "    SparkSession.builder \\\n",
    "                .master(\"local\")\n",
    "                .appName(\"World Count\")\n",
    "                .getOrCreate()\n",
    ")\n",
    "file_path = r\"C:\\Users\\brian\\Desktop\\JUNSOO\\Project\\ETL_DATA\\data\\ranking_2024-10-11.json\"\n",
    "df = spark.read.format('json').option(\"multiLine\", True).load(file_path)\n",
    "\n",
    "# 직업명을 제대로 채우기\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType , DoubleType\n",
    "df = df.select(F.explode(\"ranking\").alias(\"USER\"))\n",
    "df = df.select(\"USER.character_name\",\n",
    "               \"USER.date\",\n",
    "               \"USER.class_name\",\n",
    "               \"USER.sub_class_name\",\n",
    "               \"USER.character_level\",\n",
    "               \"USER.character_exp\",\n",
    "               \"USER.ranking\")\n",
    "df = df.withColumn(\"class\",df[\"sub_class_name\"])\n",
    "df = df.withColumn(\"class\",F.when(df[\"sub_class_name\"]== \"\", df[\"class_name\"]) \\\n",
    "                            .otherwise(df[\"class\"]))\n",
    "df = df.drop(\"class_name\",\"sub_class_name\")\n",
    "\n",
    "\n",
    "# 각 유저의 위치한 지역 컬럼추가\n",
    "df = df.withColumn(\"status\",\n",
    "                   F.when(df[\"character_level\"]>=290,\"Tallahart\") \\\n",
    "                    .when((df[\"character_level\"]<=289)&(df[\"character_level\"]>=285),\"Carcion\") \\\n",
    "                    .when((df[\"character_level\"]<=284)&(df[\"character_level\"]>=280),\"Arteria\") \\\n",
    "                    .when((df[\"character_level\"]<=279)&(df[\"character_level\"]>=275),\"Dowonkyung\") \\\n",
    "                    .when((df[\"character_level\"]<=274)&(df[\"character_level\"]>=270),\"Odium\") \\\n",
    "                    .when((df[\"character_level\"]<=269)&(df[\"character_level\"]>=265),\"HotelArcs\") \\\n",
    "                    .when((df[\"character_level\"]<=264)&(df[\"character_level\"]>=260),\"Cernium\") \\\n",
    "                    .otherwise(\"AcaneRiver\"))\n",
    "\n",
    "file_path = r\"C:\\Users\\brian\\Desktop\\JUNSOO\\rankingflow\\data\\maple_exp.csv\"\n",
    "schema = StructType([\n",
    "    StructField(\"row_number\",IntegerType(),True),\n",
    "    StructField(\"level\",IntegerType(),True),\n",
    "    StructField(\"need_exp\",DoubleType(), True)\n",
    "])\n",
    "exp_df = spark.read.format('csv').schema(schema).option(\"multiLine\", True).load(f\"{file_path}\")\n",
    "exp_df.show(10)\n",
    "exp_df = exp_df.dropna()\n",
    "exp_df = exp_df.select(\"level\",\"need_exp\")\n",
    "exp_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+---------------+---------------+-------+-----------------+---------+\n",
      "|character_name|      date|character_level|  character_exp|ranking|            class|   status|\n",
      "+--------------+----------+---------------+---------------+-------+-----------------+---------+\n",
      "|          버터|2024-10-11|            297|843016259192919|      1|       나이트로드|Tallahart|\n",
      "|          헨쇼|2024-10-11|            296|759870313066254|      2|             아델|Tallahart|\n",
      "|   케인WWE챔프|2024-10-11|            296| 24509577197550|      3|       배틀메이지|Tallahart|\n",
      "|          벨벨|2024-10-11|            295|762723872665559|      4|       스트라이커|Tallahart|\n",
      "|       검성OGC|2024-10-11|            295|557321451486306|      5|           히어로|Tallahart|\n",
      "|       Lacheln|2024-10-11|            295|492644225241999|      6|             은월|Tallahart|\n",
      "|          곤주|2024-10-11|            295|426659239260704|      7|아크메이지(불,독)|Tallahart|\n",
      "|          광선|2024-10-11|            295|416194201863297|      8|             제논|Tallahart|\n",
      "|      Kiss예진|2024-10-11|            295|406088348687129|      9|             아델|Tallahart|\n",
      "|          중뒹|2024-10-11|            295|391121166504700|     10|             비숍|Tallahart|\n",
      "+--------------+----------+---------------+---------------+-------+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_status = df.groupBy(\"class\").pivot(\"Status\").agg(F.count(\"Status\"))\n",
    "df.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
