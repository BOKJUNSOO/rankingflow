{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------------+\n",
      "|row_number|level|         need_exp|\n",
      "+----------+-----+-----------------+\n",
      "|      NULL| NULL|             NULL|\n",
      "|         0|  260|1.731919984062E12|\n",
      "|         1|  261|1.749239183902E12|\n",
      "|         2|  262|1.766731575741E12|\n",
      "|         3|  263|1.784398891498E12|\n",
      "|         4|  264|1.802242880412E12|\n",
      "|         5|  265|2.342915744535E12|\n",
      "|         6|  266| 2.36634490198E12|\n",
      "|         7|  267|2.390008350999E12|\n",
      "|         8|  268|2.413908434508E12|\n",
      "+----------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-----------------+\n",
      "|level|         need_exp|\n",
      "+-----+-----------------+\n",
      "|  260|1.731919984062E12|\n",
      "|  261|1.749239183902E12|\n",
      "|  262|1.766731575741E12|\n",
      "|  263|1.784398891498E12|\n",
      "|  264|1.802242880412E12|\n",
      "|  265|2.342915744535E12|\n",
      "|  266| 2.36634490198E12|\n",
      "|  267|2.390008350999E12|\n",
      "|  268|2.413908434508E12|\n",
      "|  269|2.438047518853E12|\n",
      "+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## USER 테이블 build\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = (\n",
    "    SparkSession.builder \\\n",
    "                .master(\"local\")\n",
    "                .appName(\"World Count\")\n",
    "                .getOrCreate()\n",
    ")\n",
    "file_path = r\"C:\\Users\\brian\\Desktop\\JUNSOO\\Project\\ETL_DATA\\data\\ranking_2024-10-11.json\"\n",
    "df = spark.read.format('json').option(\"multiLine\", True).load(file_path)\n",
    "\n",
    "# 직업명을 제대로 채우기\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType , DoubleType\n",
    "df = df.select(F.explode(\"ranking\").alias(\"USER\"))\n",
    "df = df.select(\"USER.character_name\",\n",
    "               \"USER.date\",\n",
    "               \"USER.class_name\",\n",
    "               \"USER.sub_class_name\",\n",
    "               \"USER.character_level\",\n",
    "               \"USER.character_exp\",\n",
    "               \"USER.ranking\")\n",
    "df = df.withColumn(\"class\",df[\"sub_class_name\"])\n",
    "df = df.withColumn(\"class\",F.when(df[\"sub_class_name\"]== \"\", df[\"class_name\"]) \\\n",
    "                            .otherwise(df[\"class\"]))\n",
    "df = df.drop(\"class_name\",\"sub_class_name\")\n",
    "\n",
    "\n",
    "# 각 유저의 위치한 지역 컬럼추가\n",
    "df = df.withColumn(\"status\",\n",
    "                   F.when(df[\"character_level\"]>=290,\"Tallahart\") \\\n",
    "                    .when((df[\"character_level\"]<=289)&(df[\"character_level\"]>=285),\"Carcion\") \\\n",
    "                    .when((df[\"character_level\"]<=284)&(df[\"character_level\"]>=280),\"Arteria\") \\\n",
    "                    .when((df[\"character_level\"]<=279)&(df[\"character_level\"]>=275),\"Dowonkyung\") \\\n",
    "                    .when((df[\"character_level\"]<=274)&(df[\"character_level\"]>=270),\"Odium\") \\\n",
    "                    .when((df[\"character_level\"]<=269)&(df[\"character_level\"]>=265),\"HotelArcs\") \\\n",
    "                    .when((df[\"character_level\"]<=264)&(df[\"character_level\"]>=260),\"Cernium\") \\\n",
    "                    .otherwise(\"AcaneRiver\"))\n",
    "\n",
    "file_path = r\"C:\\Users\\brian\\Desktop\\JUNSOO\\rankingflow\\data\\maple_exp.csv\"\n",
    "schema = StructType([\n",
    "    StructField(\"row_number\",IntegerType(),True),\n",
    "    StructField(\"level\",IntegerType(),True),\n",
    "    StructField(\"need_exp\",DoubleType(), True)\n",
    "])\n",
    "exp_df = spark.read.format('csv').schema(schema).option(\"multiLine\", True).load(f\"{file_path}\")\n",
    "exp_df.show(10)\n",
    "exp_df = exp_df.dropna()\n",
    "exp_df = exp_df.select(\"level\",\"need_exp\")\n",
    "exp_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-------+-------+----------+---------+\n",
      "|            class|      date|Arteria|Carcion|Dowonkyung|Tallahart|\n",
      "+-----------------+----------+-------+-------+----------+---------+\n",
      "|           카이저|2024-10-11|    146|     54|        85|       12|\n",
      "|         블래스터|2024-10-11|     86|     36|        41|        5|\n",
      "|             아란|2024-10-11|    159|    102|       104|       19|\n",
      "|           초보자|2024-10-11|      5|   NULL|         6|     NULL|\n",
      "|       패스파인더|2024-10-11|    410|    243|       278|       24|\n",
      "|아크메이지(불,독)|2024-10-11|    549|    382|       338|       67|\n",
      "|           시티즌|2024-10-11|      1|   NULL|         2|     NULL|\n",
      "|             제논|2024-10-11|     92|     63|        74|       15|\n",
      "|             라라|2024-10-11|    268|     87|       190|       16|\n",
      "|       캐논마스터|2024-10-11|    156|    108|       115|       25|\n",
      "|             제로|2024-10-11|    286|    151|       197|       30|\n",
      "|             호영|2024-10-11|    304|    163|       185|       25|\n",
      "|       보우마스터|2024-10-11|    181|    108|       127|       13|\n",
      "|       데몬어벤져|2024-10-11|    178|    107|       121|       20|\n",
      "|     플레임위자드|2024-10-11|    103|     58|        62|       16|\n",
      "|     윈드브레이커|2024-10-11|    486|    259|       336|       24|\n",
      "|           카데나|2024-10-11|    100|     67|        53|        6|\n",
      "|     엔젤릭버스터|2024-10-11|    345|    140|       240|       33|\n",
      "|             캡틴|2024-10-11|     85|     50|        56|        8|\n",
      "|         키네시스|2024-10-11|     90|     51|        60|        9|\n",
      "+-----------------+----------+-------+-------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_status = df.groupBy(\"class\",\"date\").pivot(\"status\").agg(F.count(\"status\"))\n",
    "class_status.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
